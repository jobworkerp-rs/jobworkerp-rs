# Notice: ALL TIME UNIT WITHOUT EXPLICITLY SPECIFIED IS MILLISECONDS

############################
# storage
############################

# storage options (hybrid, rdb, not recommended redis)
STORAGE_TYPE=hybrid
#STORAGE_TYPE=rdb


# db setting (USING STORAGE_TYPE={hybrid,rdb})
# (mysql or sqlite3)

## mysql seting (values: CI job)
MYSQL_HOST= "db"
MYSQL_PORT= "3306"
MYSQL_USER= "mysql"
MYSQL_PASSWORD= "mysql"
MYSQL_DBNAME= "test"
MYSQL_MAX_CONNECTIONS=20 # deadpool option

## sqlite3 setting
#SQLITE_HOST=       ""      # not available
#SQLITE_PORT=       ""      # not available
#SQLITE_USER=       ""      # not available
#SQLITE_PASSWORD=   ""      # not available
#SQLITE_DBNAME= "jobworkerp.sqlite3"
#SQLITE_MAX_CONNECTIONS=20

# redis setting (USING STORAGE_TYPE={hybrid,redis})
# (not available for redis cluster (pubsub))
REDIS_USERNAME          = ""
REDIS_PASSWORD          = ""
REDIS_URL               = "redis://redis:6379"
REDIS_POOL_CREATE_TIMEOUT_MSEC = 5000
REDIS_POOL_WAIT_TIMEOUT_MSEC = 60000
REDIS_POOL_RECYCLE_TIMEOUT_MSEC = 5000
REDIS_POOL_SIZE         = 20

# memory cache setting (stretto: consider cost of a record as 1)
MEMORY_CACHE_NUM_COUNTERS=12960
MEMORY_CACHE_MAX_COST=1296
MEMORY_CACHE_USE_METRICS=true

########################################################
# job queueing, recovery from rdb (hybrid only)
########################################################

# seconds for expiring DIRECT or LISTEN_AFTER job result (storage_type=hybrid (or redis))
JOB_QUEUE_EXPIRE_JOB_RESULT_SECONDS=3600
# fetch interval msecs for periodic or run_after job
JOB_QUEUE_FETCH_INTERVAL=1000

# restore jobs from rdb at startup
# (ex. use to restore jobs remaining when the worker process panics and crashes)
# (same function as JobRestoreService/Restore)
# only enable when STORAGE_TYPE=hybrid
STORAGE_RESTORE_AT_STARTUP=false

# concurrency for default channel (worker.channel=None)
WORKER_DEFAULT_CONCURRENCY=8

# additional queue channel
# (separate by comma)
# worker process fetch jobs only from specified channels.
WORKER_CHANNELS="channel1,channel2"
# worker channels concurrency (same sequence as WORKER_CHANNELS)
WORKER_CHANNEL_CONCURRENCIES=4,1

############################
# logging, metrics
############################
# trace, debug, info, warn, error
LOG_LEVEL=debug
# log output file path
LOG_FILE_DIR=log/
# log file format to jeson
LOG_USE_JSON=true
# output stdout or not
LOG_USE_STDOUT=true

# timezone
TZ_OFFSET_HOURS = 9

# can specify each one: JAEGER_ADDR or ZIPKIN_ADDR (OTLP_ADDR is under testing...)
#JAEGER_ADDR="jaeger.istio-system.svc.cluster.local:6831"
#ZIPKIN_ADDR="http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans"
#OTLP_ADDR="http://otel-collector.default.svc.cluster.local:4317" # UNDER TESTING

############################
# front server
############################

# grpc listen addr
GRPC_ADDR=0.0.0.0:9000

# use grpc web (for connect js etc)
USE_GRPC_WEB=true


############################
# worker(runner) specific settings
############################

# for docker runner
# docker GID. use value: $(stat -c '%g' /var/run/docker.sock)
DOCKER_GID=963

# plugin directory (find *.so in this dir)
PLUGINS_RUNNER_DIR="./target/debug/"

# for slack worker (notification in result specify as next_workers="-1" in worker definition)
SLACK_TITLE="Result Notification"
SLACK_BOT_TOKEN="FILLIN_YOUR_TOKEN"
SLACK_CHANNEL=#random
SLACK_NOTIFY_SUCCESS=true
SLACK_NOTIFY_FAILURE=true
