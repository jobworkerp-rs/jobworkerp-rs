# Notice: ALL TIME UNIT WITHOUT EXPLICITLY SPECIFIED IS MILLISECONDS

############################
# storage
############################

# storage options (Standalone(sqlite + memory) or Scalable (need redis and mysql).)
STORAGE_TYPE=Standalone
#STORAGE_TYPE=Scalable

# db setting
# (mysql or sqlite3)

# sqlite3 setting
SQLITE_URL= "sqlite3://jobworkerp.sqlite3"
SQLITE_MAX_CONNECTIONS=20

## mysql setting
#MYSQL_HOST=       "127.0.0.1"      # not available
#MYSQL_PORT=       "3306"      # not available
#MYSQL_USER=       "mysql"      # not available
#MYSQL_PASSWORD=   "mysql"      # not available
#MYSQL_DBNAME=     "test"
#MYSQL_MAX_CONNECTIONS=20

# redis setting (USING STORAGE_TYPE={hybrid,redis})
# (not available for redis cluster (pubsub))
#REDIS_USERNAME          = ""
#REDIS_PASSWORD          = ""
#REDIS_URL               = "redis://redis:6379"
#REDIS_POOL_CREATE_TIMEOUT_MSEC = 5000
#REDIS_POOL_WAIT_TIMEOUT_MSEC = 60000
#REDIS_POOL_RECYCLE_TIMEOUT_MSEC = 5000
#REDIS_POOL_SIZE         = 20

# memory cache setting (stretto: consider cost of a record as 1)
MEMORY_CACHE_NUM_COUNTERS=1296000
MEMORY_CACHE_MAX_COST=1296
MEMORY_CACHE_USE_METRICS=true
MEMORY_CACHE_TTL_SEC=600 # for moka cache

########################################################
# job queueing, recovery from rdb (hybrid only)
########################################################

# seconds for expiring DIRECT or LISTEN_AFTER job result
JOB_QUEUE_EXPIRE_JOB_RESULT_SECONDS=3600
# fetch interval msecs for periodic or run_after job
JOB_QUEUE_FETCH_INTERVAL=1000

# restore jobs from rdb at startup
# (ex. use to restore jobs remaining when the worker process panics and crashes)
# (same function as JobRestoreService/Restore)
# only enable when STORAGE_TYPE=Scalable
STORAGE_RESTORE_AT_STARTUP=false

# concurrency for default channel (worker.channel=None)
WORKER_DEFAULT_CONCURRENCY=8

# additional queue channel
# (separate by comma)
# worker process fetch jobs only from specified channels.
WORKER_CHANNELS="channel1,channel2"
# worker channels concurrency (same sequence as WORKER_CHANNELS)
WORKER_CHANNEL_CONCURRENCIES=4,1

############################
# logging, metrics
############################
# logging level base
RUST_LOG=debug,h2=info,sqlx=info,opentelemetry=info
# app name
LOG_APP_NAME="jobworkerp-rs"
# trace, debug, info, warn, error
LOG_LEVEL=info
# log output file path
LOG_FILE_DIR=log/
# log file format to jeson
LOG_USE_JSON=true
# output stdout or not
LOG_USE_STDOUT=true

# can specify each one: ZIPKIN_ADDR or OTLP_ADDR (under testing...)
#ZIPKIN_ADDR="http://zipkin.istio-system.svc.cluster.local:9411/api/v2/spans"
#OTLP_ADDR="http://otel-collector.default.svc.cluster.local:4317" # UNDER TESTING

############################
# front server
############################

# grpc listen addr
GRPC_ADDR=0.0.0.0:9000

# use grpc web (for connect js etc)
USE_GRPC_WEB=true

MAX_FRAME_SIZE=16777215 # 16MB - 1

############################
# worker(runner) specific settings
############################

# for docker runner
# docker GID. use value: $(stat -c '%g' /var/run/docker.sock)
DOCKER_GID=963

# plugin directory (find *.so in this dir)
#PLUGINS_RUNNER_DIR="/home/jobworkerp/plugins/"
PLUGINS_RUNNER_DIR="./target/release/"
#PLUGINS_RUNNER_DIR="./plugins/"

# timezone
TZ_OFFSET_HOURS = 9


WORKFLOW_TASK_DEFAULT_TIMEOUT=1200 #20 min
#WORKFLOW_HTTP_USER_AGENT=workflow/1.0
WORKFLOW_HTTP_TIMEOUT_SEC=20 # for fetching resource
WORKFLOW_CHECKPOINT_EXPIRE_TIME_SEC=86400 # 1day
WORKFLOW_CHECKPOINT_MAX_COUNT=100000


# for genai llm (set model name property in llm runner settings)
OPENAI_API_KEY="YOUR KEY"
ANTHROPIC_API_KEY="YOUR KEY"
GEMINI_API_KEY="YOUR KEY"

